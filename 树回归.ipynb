{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵：\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "切分矩阵：\n",
      " [[0. 1. 0. 0.]] \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "树回归结果：\n",
      " {'spInd': 0, 'spVal': 0.48813, 'left': 1.0180967672413792, 'right': -0.04465028571428572}\n"
     ]
    }
   ],
   "source": [
    "#..........................案例1:\n",
    "#.......................... 理解树回归\n",
    "#...............对于非线性问题，可以考虑切分后再进行回归，这就是树回归\n",
    "#.......CART（回归分类树），可用于分类和回归\n",
    "# 之前决策树采取的ID3算法，ID3切法，一旦切了，这个特征之后不起作用，并且不能处理连续型\n",
    "# CART采用的二元切分\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 切分数据函数\n",
    "def binSplitDataSet(dataSet, feature, value):\n",
    "    mat0 = dataSet[np.nonzero(dataSet[:,feature] > value)[0],:]\n",
    "    mat1 = dataSet[np.nonzero(dataSet[:,feature] <= value)[0],:]\n",
    "    return mat0,mat1\n",
    "test=np.mat(np.eye(4))\n",
    "print('矩阵：\\n',test)\n",
    "m1,m2=binSplitDataSet(test,1,0.5)\n",
    "print('切分矩阵：\\n',m1,'\\n',m2) # 指定列进行二元切分\n",
    "# 叶节点\n",
    "def regLeaf(dataSet): #returns the value used for each leaf\n",
    "    return np.mean(dataSet[:,-1])\n",
    "# 计算误差\n",
    "def regErr(dataSet):\n",
    "    return np.var(dataSet[:,-1]) * np.shape(dataSet)[0]\n",
    "# 遍历所有的特征及其可能的取值来找到使误差最小化的切分阈值\n",
    "def chooseBestSplit(dataSet, leafType=regLeaf, errType=regErr, ops=(1,4)):\n",
    "    # 量tolS是容许的误差下降值，tolN是切分的最少样本数\n",
    "    tolS = ops[0]; tolN = ops[1]\n",
    "    #if all the target variables are the same value: quit and return value\n",
    "    if len(set(dataSet[:,-1].T.tolist()[0])) == 1: #exit cond 1\n",
    "        return None, leafType(dataSet)\n",
    "    m,n = np.shape(dataSet)\n",
    "    #the choice of the best feature is driven by Reduction in RSS error from mean\n",
    "    S = errType(dataSet)\n",
    "    bestS = np.inf; bestIndex = 0; bestValue = 0\n",
    "    for featIndex in range(n-1):\n",
    "        for splitVal in set(dataSet[:,featIndex].flatten().A[0]):\n",
    "            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)\n",
    "            if (np.shape(mat0)[0] < tolN) or (np.shape(mat1)[0] < tolN): continue\n",
    "            newS = errType(mat0) + errType(mat1)\n",
    "            if newS < bestS:\n",
    "                bestIndex = featIndex\n",
    "                bestValue = splitVal\n",
    "                bestS = newS\n",
    "    #if the decrease (S-bestS) is less than a threshold don't do the split\n",
    "    if (S - bestS) < tolS:\n",
    "        return None, leafType(dataSet) #exit cond 2\n",
    "    mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "    if (np.shape(mat0)[0] < tolN) or (np.shape(mat1)[0] < tolN):  #exit cond 3\n",
    "        return None, leafType(dataSet)\n",
    "    return bestIndex,bestValue #returns the best feature to split on\n",
    "                              #and the value used for that split\n",
    "# 创建回归树\n",
    "def createTree(dataSet, leafType=regLeaf, errType=regErr, ops=(1,4)): #assume dataSet is NumPy Mat so we can array filtering\n",
    "    feat, val = chooseBestSplit(dataSet, leafType, errType, ops) #choose the best split\n",
    "    if feat == None: return val #if the splitting hit a stop condition return val\n",
    "    retTree = {}\n",
    "    retTree['spInd'] = feat\n",
    "    retTree['spVal'] = val\n",
    "    lSet, rSet = binSplitDataSet(dataSet, feat, val)\n",
    "    retTree['left'] = createTree(lSet, leafType, errType, ops)\n",
    "    retTree['right'] = createTree(rSet, leafType, errType, ops)\n",
    "    return retTree\n",
    "dta=pd.read_table(r'C:\\Users\\Wudey\\Desktop\\machinelearninginaction\\Ch09\\ex00.txt',header=None)\n",
    "print('树回归结果：\\n',createTree(np.mat(dta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "树回归结果：\n",
      " {'spInd': 0, 'spVal': 0.48813, 'left': {'spInd': 0, 'spVal': 0.620599, 'left': 0.9852403058823527, 'right': 1.1081870645161291}, 'right': -0.04465028571428572}\n",
      "树回归结果(后剪枝)：\n",
      " {'spInd': 0, 'spVal': 0.48813, 'left': {'spInd': 0, 'spVal': 0.620599, 'left': 0.9852403058823527, 'right': 1.1081870645161291}, 'right': -0.04465028571428572}\n"
     ]
    }
   ],
   "source": [
    "#..........................案例2:\n",
    "#.......................... 剪枝：通过降低决策树的复杂度来避免过拟合的过程称为剪枝（pruning）\n",
    "#............预剪枝：在训练过程中剪枝，chooseBestSplit中的opt其实就是预剪枝。\n",
    "print('树回归结果：\\n',createTree(np.mat(dta),ops=(0.2,4)))\n",
    "# 这个结果的树节点就比较多\n",
    "# 如果ops[0]=0，每个点都会是树节点。我们不知道结果应该是怎样的，这样剪枝效果并不好。\n",
    "#............后剪枝：指定参数使得结果比较复杂，方便剪枝。\n",
    "# 后剪枝需要同时考虑训练结果和测试集，可以合并的则合并（总误差方差减少）\n",
    "# 判断是否决策树\n",
    "def isTree(obj):\n",
    "    return (type(obj).__name__=='dict')\n",
    "# 用于判断是否有测试集,没有的话就return均值\n",
    "def getMean(tree):\n",
    "    if isTree(tree['right']): tree['right'] = getMean(tree['right'])\n",
    "    if isTree(tree['left']): tree['left'] = getMean(tree['left'])\n",
    "    return (tree['left']+tree['right'])/2.0\n",
    "# 后剪枝\n",
    "def prune(tree, testData):\n",
    "    if np.shape(testData)[0] == 0: return getMean(tree) #if we have no test data collapse the tree\n",
    "    if (isTree(tree['right']) or isTree(tree['left'])):#if the branches are not trees try to prune them\n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal'])\n",
    "    if isTree(tree['left']): tree['left'] = prune(tree['left'], lSet)\n",
    "    if isTree(tree['right']): tree['right'] =  prune(tree['right'], rSet)\n",
    "    #if they are now both leafs, see if we can merge them\n",
    "    if not isTree(tree['left']) and not isTree(tree['right']):\n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal'])\n",
    "        errorNoMerge = sum(np.power(lSet[:,-1] - tree['left'],2)) +\\\n",
    "            sum(np.power(rSet[:,-1] - tree['right'],2))\n",
    "        treeMean = (tree['left']+tree['right'])/2.0\n",
    "        errorMerge = sum(np.power(testData[:,-1] - treeMean,2))\n",
    "        if errorMerge < errorNoMerge:\n",
    "            print(\"merging\")\n",
    "            return treeMean\n",
    "        else: return tree\n",
    "    else: return tree\n",
    "tree=createTree(np.mat(dta),ops=(0.2,4))\n",
    "print('树回归结果(后剪枝)：\\n',prune(tree,np.mat(dta.iloc[0:30,:].values)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "树回归：\n",
      " {'spInd': 0, 'spVal': 0.48813, 'left': matrix([[ 1.21832215],\n",
      "        [-0.27389304]]), 'right': matrix([[ 0.00779999],\n",
      "        [-0.22210371]])}\n"
     ]
    }
   ],
   "source": [
    "#..........................案例3:\n",
    "#.......................... 树回归（2）：分段线性回归\n",
    "# 线性回归\n",
    "def linearSolve(dataSet):   #helper function used in two places\n",
    "    m,n = np.shape(dataSet)\n",
    "    X = np.mat(np.ones((m,n))) # create a copy of data with 1 in 0th postion\n",
    "    X[:,1:n] = dataSet[:,0:n-1]; Y = dataSet[:,-1] #and strip out Y\n",
    "    xTx = X.T*X\n",
    "    if np.linalg.det(xTx) == 0.0:\n",
    "        raise NameError('This matrix is singular, cannot do inverse,\\n\\\n",
    "        try increasing the second value of ops')\n",
    "    ws = xTx.I * (X.T * Y)\n",
    "    return ws,X,Y\n",
    "# 回归系数\n",
    "def modelLeaf(dataSet):#create linear model and return coeficients\n",
    "    ws,X,Y = linearSolve(dataSet)\n",
    "    return ws\n",
    "# 回归误差最小化\n",
    "def modelErr(dataSet):\n",
    "    ws,X,Y = linearSolve(dataSet)\n",
    "    yHat = X * ws\n",
    "    return sum(np.power(Y - yHat,2))\n",
    "print('树回归：\\n',createTree(np.mat(dta),modelLeaf,modelErr,(1,2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R方（二分回归）：\n",
      " [[1.         0.96408523]\n",
      " [0.96408523 1.        ]]\n",
      "R方（分段回归）：\n",
      " [[1.         0.97604122]\n",
      " [0.97604122 1.        ]]\n",
      "R方（线性回归）：\n",
      " 0.943468\n"
     ]
    }
   ],
   "source": [
    "#..........................案例4:\n",
    "#.......................... 比较模型结果\n",
    "def regTreeEval(model, inDat):\n",
    "    return float(model)\n",
    "def modelTreeEval(model, inDat):\n",
    "    n = np.shape(inDat)[1]\n",
    "    X = np.mat(np.ones((1,n+1)))\n",
    "    X[:,1:n+1]=inDat\n",
    "    return float(X*model)\n",
    "def treeForeCast(tree, inData, modelEval=regTreeEval):\n",
    "    if not isTree(tree): return modelEval(tree, inData)\n",
    "    if inData[tree['spInd']] > tree['spVal']:\n",
    "        if isTree(tree['left']): return treeForeCast(tree['left'], inData, modelEval)\n",
    "        else: return modelEval(tree['left'], inData)\n",
    "    else:\n",
    "        if isTree(tree['right']): return treeForeCast(tree['right'], inData, modelEval)\n",
    "        else: return modelEval(tree['right'], inData)\n",
    "def createForeCast(tree, testData, modelEval=regTreeEval):\n",
    "    m=len(testData)\n",
    "    yHat = np.mat(np.zeros((m,1)))\n",
    "    for i in range(m):\n",
    "        yHat[i,0] = treeForeCast(tree, np.mat(testData[i]), modelEval)\n",
    "    return yHat\n",
    "dta=pd.read_table(r'C:\\Users\\Wudey\\Desktop\\machinelearninginaction\\Ch09\\bikeSpeedVsIq.txt',header=None)\n",
    "train,test=dta.iloc[0:200,:].values,dta.iloc[200:,:].values\n",
    "mytree1=createTree(np.mat(train),ops=(1,20))\n",
    "yhat=createForeCast(mytree1,test[:,0])\n",
    "print('R方（二分回归）：\\n',np.corrcoef(yhat.flatten().A[0],test[:,1]))\n",
    "mytree2=createTree(np.mat(train),modelLeaf,modelErr,ops=(1,20))\n",
    "yhat=createForeCast(mytree2,test[:,0],modelTreeEval)\n",
    "print('R方（分段回归）：\\n',np.corrcoef(yhat.flatten().A[0],test[:,1]))\n",
    "print('R方（线性回归）：\\n','0.943468')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Not_Scrapy)",
   "language": "python",
   "name": "pycharm-668536be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}