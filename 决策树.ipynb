{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 在划分数据集之前之后信息发生的变化称为信息增益，获得信息增益最高的特征就是最好的选择（ID3法）。\n",
    "- 信息的期望称之为熵。假设一组数值/字符串（xt）分为n类，在第i类中，xt的信息指的是落在i类的概率的对数的负值l(xit)=-log2(p(xit))，则该组的熵为ΣtΣi[p(xit)l(xit)]\n",
    "- 熵越大，混合的数据也越多，无序程度越大。通过不同的划分使组的熵最小（信息增益划分法）\n",
    "- 另一种度量集合无序程度的方法是基尼不纯度（Gini impurity），简单地说就是从一个数据集中随机选取子项，度量其被错误分类到其他分组里的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataSet最后一列的熵值： 0.9709505944546686\n",
      "dataSet增加一种分类后最后一列的熵值： 1.3709505944546687\n",
      "dataSet的最好的分类列：第0列\n"
     ]
    }
   ],
   "source": [
    "#..........................案例1:\n",
    "#.......................... 理解信息增益\n",
    "from math import log\n",
    "import operator\n",
    "# 数据集\n",
    "dataSet = [[1, 1, 'yes'],[1, 1, 'yes'],[1, 0, 'no'],[0, 1, 'no'],[0, 1, 'no']]\n",
    "# 数据集的熵（信息的期望值）\n",
    "# 若不分组，即1组，计算yes和no的熵，yes信息和no信息的求和\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob,2) #log base 2\n",
    "    return shannonEnt\n",
    "print(\"dataSet最后一列的熵值：\",calcShannonEnt(dataSet))\n",
    "dataSet[0][-1]='maybe'\n",
    "print(\"dataSet增加一种分类后最后一列的熵值：\",calcShannonEnt(dataSet))\n",
    "# 抽取数据\n",
    "def splitDataSet(dataSet, axis, value): # axis列表中的第几个，value根据值筛选\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]  # 删掉取值的这一类\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "# 若分组，即根据前面的信息分组，计算yes和no的熵，yes信息和no信息的组内和组间的总和\n",
    "# 选择最好的划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1     # 最后一列是标签\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    for i in range(numFeatures):        #iterate over all the features\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)       # 每一列的分类标签列表\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value) # 用特征划分数据集\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet) # 求每个数据集的熵并求和\n",
    "        infoGain = baseEntropy - newEntropy     # 信息增益\n",
    "        if (infoGain > bestInfoGain):       #compare this to the best gain so far\n",
    "            bestInfoGain = infoGain         # 挑选最好的信息增益\n",
    "            bestFeature = i\n",
    "    return bestFeature\n",
    "print(\"dataSet的最好的分类列：第%s列\" % chooseBestFeatureToSplit(dataSet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataSet的决策树 {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'maybe'}}}}\n",
      "预测结果： maybe\n",
      "预测结果： no\n"
     ]
    }
   ],
   "source": [
    "#..........................案例2:\n",
    "#.......................... 理解决策树\n",
    "# 设定输出\n",
    "label = ['no surfacing','flippers']\n",
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "# 决策树\n",
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList): # 如果分类变量是常数，不再分类\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1: # 遍历完所有特征\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet) # 选出最好的一列\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]       #copy all of labels, so trees don't mess up existing labels\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)\n",
    "    return myTree\n",
    "print(\"dataSet的决策树\",createTree(dataSet,label))\n",
    "# 决策树的可视化，这里先跳过\n",
    "# 决策树估计\n",
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    key = testVec[featIndex]\n",
    "    valueOfFeat = secondDict[key]\n",
    "    if isinstance(valueOfFeat, dict): # 是否仍是字典\n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else: classLabel = valueOfFeat\n",
    "    return classLabel\n",
    "label = ['no surfacing','flippers'] # createTree会改变label的值，因此每次都需要重新定义\n",
    "mytree=createTree(dataSet,label)\n",
    "label = ['no surfacing','flippers']\n",
    "print(\"预测结果：\",classify(mytree,label,[1,1]))\n",
    "print(\"预测结果：\",classify(mytree,label,[0,1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-668536be",
   "language": "python",
   "display_name": "PyCharm (Not_Scrapy)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}