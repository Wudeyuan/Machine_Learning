{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1         X2  Y  con\n",
      "0 -0.017612  14.053064  0  1.0\n",
      "1 -1.395634   4.662541  1  1.0\n",
      "----\n",
      "参数值：\n",
      " [[ 0.48007329]\n",
      " [-0.6168482 ]\n",
      " [ 4.12414349]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1, 100)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#..........................案例1:\n",
    "#.......................... 理解Logistic\n",
    "# Sigmoid函数：σ(x)=1/(1+exp(-x))，将所有数据归到0-1之间\n",
    "# p(y|x;w)=σ(wx)^y[1-σ(wx)]^(1-y) # y取值0、1，期望p值尽可能大\n",
    "# 梯度上升法：Δf=(df/dx,df/dy),移动方向最佳，迭代公式为w:=w+α*Δf|w，函数的最大值\n",
    "# 梯度下降法：Δf=(df/dx,df/dy),移动方向最佳，迭代公式为w:=w-α*Δf|w，函数的最小值\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dSet=pd.read_table(r'C:\\Users\\Wudey\\Desktop\\machinelearninginaction\\Ch05\\testSet.txt',header=None)\n",
    "dSet.columns=['X1','X2','Y']\n",
    "dSet['con']=1.0 # 截距项\n",
    "print(dSet.head(2))\n",
    "# sigmoid函数\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))\n",
    "# 梯度上升\n",
    "def gradAscent(dataMatIn, classLabels):\n",
    "    dataMatrix = np.mat(dataMatIn) # X nx2\n",
    "    labelMat = np.mat(classLabels).transpose() # transpose将1xn变成nx1\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    alpha = 0.001\n",
    "    maxCycles = 500 # 最大迭代次数\n",
    "    weights = np.ones((n,1)) # 初始参数，这里为[[1],[1]]\n",
    "    for k in range(maxCycles):\n",
    "        h = sigmoid(dataMatrix*weights)     # 拟合值\n",
    "        error = (labelMat - h)              # 误差项\n",
    "        weights = weights + alpha * dataMatrix.transpose()* error # 该公式可对w求导得到\n",
    "    return weights\n",
    "print('----\\n参数值：\\n',gradAscent(dSet[['X1','X2','con']],dSet['Y']))\n",
    "\n",
    "# 随机梯度上升（用来处理数据量太大方法一难以计算的问题，效果会较差）\n",
    "def stocGradAscent0(dataMatrix, classLabels):\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    alpha = 0.01\n",
    "    weights = np.ones(n)   #initialize to all ones\n",
    "    for i in range(m):\n",
    "        h = sigmoid(np.sum(dataMatrix[i]*weights))\n",
    "        error = classLabels[i] - h\n",
    "        weights = weights + alpha * error * dataMatrix[i] # 用一行行修改权重\n",
    "    return weights\n",
    "# 改进随机梯度上升（随机梯度上升可能会有比较大的波动）\n",
    "def stocGradAscent1(dataMatrix, classLabels, numIter=150): # np.array格式即可\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    weights = np.ones(n)   #initialize to all ones\n",
    "    for j in range(numIter):\n",
    "        dataIndex = range(m)\n",
    "        for i in range(m):\n",
    "            alpha = 4/(1.0+j+i)+0.0001    #apha decreases with iteration, does not\n",
    "            randIndex = int(np.random.uniform(0,len(dataIndex))) # 随机选取，减少波动\n",
    "            h = sigmoid(sum(dataMatrix[randIndex]*weights))\n",
    "            error = classLabels[randIndex] - h\n",
    "            weights = weights + alpha * error * dataMatrix[randIndex]\n",
    "            del(dataIndex[randIndex])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#..........................案例2:\n",
    "#.......................... 比较简单，实例可自行探索"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Not_Scrapy)",
   "language": "python",
   "name": "pycharm-668536be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}